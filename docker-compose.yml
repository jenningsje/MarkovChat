version: '3.6'

services:
  frontend:
    build:
      context: ./Markov-GUI/Dockerfile
    ports:
      - "3000:3000"
    environment:
      - 'OPENAI_API_HOST=http://backend:8889'  # Use the service name for backend
      - 'OPENAI_API_TYPE=azure'
    networks:
      - mynetwork

  backend:
    build:
      context: ./Markov-Bot/Dockerfile
    ports:
      - "8889:8889"
    networks:
      - mynetwork

  nginx:
    image: nginx:latest
    ports:
      - "3003:80"
    security_opt:
      - seccomp:~/seccomp/seccomp.json
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./html:/etc/nginx/html
    depends_on:
      - frontend
      - backend  # Ensure nginx waits for both chatgpt and backend
    networks:
      - mynetwork
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 1G

networks:
  mynetwork:

